{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 Implement KNN classification, using the sklearn package. We learned how to do this in class. \n",
    "# See also: http://scikit-learn.org/stable/modules/neighbors.html#nearest- neighbors-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from seaborn import plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2 Use the sklearn package to implement cross-validation for your classifier. \n",
    "#Use 5 folds for your cross-validation. \n",
    "# See also: http://scikit-learn.org/stable/modules/cross_validation.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " import numpy as np\n",
    "from sklearn import cross_validation\n",
    " from sklearn import datasets\n",
    " from sklearn import svm\n",
    "\n",
    " iris = datasets.load_iris()\n",
    " iris.data.shape, iris.target.shape\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets, feature_selection\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "import numpy as np\n",
    " from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 Use your KNN classifier and cross-validation code from (1) and (2) above to determine \n",
    "# the optimal value of K (number of nearest neighbors to consult) for this Iris dataset. \n",
    "# Hint: This hyperparameter will be a number between 1 and 150 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4 Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range \n",
    "#4 of K that you consider interesting. Explain in words what you are seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 Now, write your own implementation of cross-validation in Python without using the \n",
    "# cross-validation methods from sklearn. Cross validation is a very important concept. \n",
    "# Implementing it yourself in Python is the best way to learn and understand it. \n",
    "# Compare the results of your cross-validation code with your results using the \n",
    "# cross-validation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6 EXTRA CREDIT 1: Using the value of K obtained in (3) above, vary the number of \n",
    "# folds used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. \n",
    "# How does classifier accuracy vary with the number of folds used? Do you think there exists \n",
    "# an optimal number of folds to use for this particular problem? Why or why not? ï¿¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRA CREDIT 2: Write your own implementation of KNN classification in Python, \n",
    "# without using the methods from sklearn. Compare your results with the results you \n",
    "# obtained using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
